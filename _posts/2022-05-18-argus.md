---
title:  "Ubuntu 환경에서의 Log 분석 with Argus"
excerpt: "Argus 활용 로그 분석"

categories: forensic
tags:
  - [ubuntu, log, argus]

toc: true
toc_sticky: true
 
date: 2022-5-18-22:01
last_modified_at: 2022-5-18
---

#### Argus
* * *
- IDS의 대표적인 오픈소스 : Snort, suricata, argus IDS
- Argus IDS의 본체는 네트워크 중간에 배치, argus의 사용자 콘솔은 사무실에 배치

![](../../assets/images/20220518-132121.png){: .center}

##### argus를 위한 툴 설치

```bash
$ sudo apt-get install -y flex bison make
$ cd ~/Download
$ tar -zxvf argus-clients-3.0.8/
$ cd argus-clients-3.0.8/
$ sudo ./configure
$ sudo make && make install
```

##### argus 테스트

```bash
$ cd ..
$ ra --help
$ ra -nzr 1_merged_total.arg -s saddr,sport,daddr,dport
$ ra -nzr 1_merged_total.arg - "src host 192.168.1.122 and udp"
```

##### DNS(Domain Name Service)
- 정방향 조회 : Domain Name -> ip
- 역방향 조회 : ip -> Domain Name
- DNS Record
  - A : 정방향 조회 (IPv4 주소를 알려줌)
  - AAAA 또는 A6 : 정방향 조회 (IPv6 주소를 알려줌)
  - PTR(pointer) : 역방향 조회
  - cname : 별칭
  - NS : Name server 의 준말

```bash
$ tail -10 2_dns.log
```

![](../../assets/images/20220518-141435.png){: .center}

- 구분자 : [**]
- Query : Client 가 DNS server 에게 IP 주소를 물어볼 때
- Response : DNS Server가 Client 에게 알려준거
- 3번째 칼럼이 도메인이고, 6번째가 IP주소
- Response 이면서 A로 표시된것이 정방향 조회의 결과

![](../../assets/images/20220518-142212.png){: .center}

```bash
# 로그 분석
# awk 쓰기 위해 sed를 활용해서 [**] -> | 구분자 변경
# | 를 제거하기 위 -F"|" -F : 구분자 변경 ("|")
$ cat 2_dns.log | sed 's/\[\*\*\]/|/g' | awk -F "|" '{print $3, $6}' 
# Response 이면서 정방향 요청인 로그만 출력
# ~  : 앞의 변수를 분석하겠다.. $4~ -> $4를 분석하겠다라는 의미
# // : "//" 사이의 문자를 포함하면,,,
# "" : "" 사이의 문자와 같으면,,,
$ cat 2_dns.log | sed 's/\[\*\*\]/|/g' | awk -F "|" '$2~/Response/ && $4~"A"{print $3, $6}' | sort | uniq -c | sort -rn
```

##### 실습 [1]
**문제 1 : 출발지 : 192.168.1.0/24**

**외부의 웹 서비스(443 or 80)에 접속한 로그만 골라서 web.log에 저장.**

```bash
$ ra -nzr 1_merged_total.arg - "src net 192.168.1.0/24 and dst port (443 or 80) and tcp" > web.log
```

**문제 2 : 데이터가 너무 많으므로 중복 제거하고 출력**

```bash
$ ra -nzr 1_merged_total.arg - "src net 192.168.1.0/24 and dst port (443 or 80) and tcp" | uniq -c > web.log
```

**문제 3 : tcp 포트로 출발하는 IP 통계 출력**

```bash
$ ra -nzr 1_merged_total.arg -s saddr - "tcp" |sort | uniq -c | sort -rn
```

**문제 4 : tcp를 사용 하는 경우 상위 10개의 목적지 IP 통계**

```bash
$ ra -nzr 1_merged_total.arg -s daddr - "tcp" |sort | uniq -c | sort -rn | head -10
```

![](../../assets/images/20220518-145335.png){: .center}

**문제 4-1 : 업로드가 많은 상위 10개의 출발지 IP 통계, tcp**

```bash
$ ra -nzr 1_merged_total.arg -s sbyte,saddr - "tcp" | uniq -c|sort -rn | head -10
```

![](../../assets/images/20220518-145114.png){: .center}

##### [실습2]
**문제5 문제4에 대한 awk group by sum**

```bash
$ ra -nzr 1_merged_total.arg -s saddr,sbyte - "tcp" | sort -k 1,1 | awk 'ip==$1{sum=sum+$2;next}{print sum, ip; ip=$1; sum=$2}' | sort -rn |head -10
```

**문제6 tcp 통신하는 출발지 IP, 목적지 IP, 목적지 Port를 추출**
```bash
$ ra -nzr 1_merged_total.arg -s saddr, daddr, stime, dport - "tcp" | awk '{print $1, $2, $4 }'| sort| uniq -c | sort -rn > tcp_connection

$ ra -nzr 1_merged_total.arg -s saddr, daddr, stime, dport - "tcp" | awk '{print $1,$2,$4}' | sort | uniq -c | sort -rn > tcp_connection
```

**문제7 2_dns.log 파일에서 구분자는 파이프로 치환하고 $2에서 Response로 시작하며 $4가 A인 것들을 골라 $3와 $6만 추출하여 dns.lookup으로 저장**

```bash
# dns 테이블 생성
$ cat 2_dns.log | sed 's/\[\*\*\]/|/g' | awk -F "|" '$2~/Response/ && $4~"A"{print $3, $6}' | sort -u > dns.lookup
```

##### [실습3]

**문제 8 tcp_connection 파일에서 내부망(172.16.0.0/16, 192.168.0.0/16, 10.0.0.0/8) 대역(목적지IP)로 이동하는 트래픽을 제외하고 Top30 까지 통신 트래픽을 생성 후 dns.lookup 파일과 매칭하여 목적지 IP에 대한 도메인을 구하시오.**

```bash
# 사설 IP만 골라내면 /^172.16|^192.168|^10.0/
# 사설 IP가 아닌것은 !~/^172.16|^192.168|^10.0/
# tcp_connection에서 세번째 칼럼이 목적지 IP 주소: $3
# $3에서 사설 IP 가 아닌것을 고르려면 : $3!~/^172.16|^192.168|^10.0/
# 특수문자 escape 처리 : $3!~/^172\.16|^192\.168|^10\.0/
$ cat tcp_connection | awk '$3!~/^172\.16|^192\.168|^10\.0/ {print $2,$3,$4}' | sort | uniq -c | sort -rn | head -30 > top30
```

- top30의 목적지 주소에 대한 도메인 주소를 dns.lookup에서 찾아서 dns_matched로 저장하기


![](../../assets/images/20220518-161325.png){: .center}

```bash
# $2 : lookup의 두번째 칼럼
# $1 : lookup의 첫번째 칼럼
$ cat top30 | while read line
> do
> dip=$(echo $line | awk '{print $2}')
> domain=$(cat dns.lookup | awk -v ip=$dip '$2==ip {print $1}' | head -1)
> echo $dip $domain
> done > dns_matched
```
- blinq.in 이 제일 의심스러움
- 해당 ip 역추적 ㄱㄱ

zum.com 121.189.40.10

```bash
$ ra -nzr 1_merged_total.arg -s saddr,daddr - "dst host 188.53.211.186" | awk '{print $1}' | sort -u
```

![](../../assets/images/20220518-162013.png){: .center}

- 옆 컴퓨터랑 여차저차해서 감염되지 않았을까,,, 하는 추측

**문제 9번 SSH 트래픽을 많이 사용한 로그를 시간, sip, dip, dport 순으로 출력**

```bash
$ ra -nzr 1_merged_total.arg -s stime,saddr,sport,daddr,dport - "src port 22" | awk 'print $2' | sort | uniq -c | sort -rn
```